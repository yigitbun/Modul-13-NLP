{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs \n",
    "\n",
    "def readtext(dateiname):\n",
    "    text = ''\n",
    "    d = codecs.open(dateiname,'r','utf8')\n",
    "    for zeile in d:\n",
    "        text += str(zeile)\n",
    "    d.close()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def read_data(directories):\n",
    "    docs = []\n",
    "    for directory in directories:\n",
    "        for file in glob.glob(directory+\"/*.txt\"):\n",
    "            text = readtext(file)\n",
    "            docs.append((text,directory))\n",
    "    return docs\n",
    "\n",
    "data = read_data(['neg','pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(data)\n",
    "train_data_raw = data[80:]\n",
    "test_data_raw = data[:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def features_from_text(text, POSlist):\n",
    "    wordcounts = Counter()\n",
    "    tlen = 0\n",
    "    \n",
    "    sentlist = nltk.sent_tokenize(text,language='english')\n",
    "    for sent in sentlist:\n",
    "        tokens = nltk.word_tokenize(sent,language='english')\n",
    "        tokens = [lemma for (lemma,pos) in nltk.pos_tag(tokens) if pos in POSlist]\n",
    "        wordcounts.update(tokens)\n",
    "        tlen +=len(tokens)\n",
    "    return {w:wordcounts[w]/tlen for w in wordcounts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "poslist = ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n",
    "test_data = [(features_from_text(text,poslist),cl) for text,cl in test_data_raw]\n",
    "train_data = [(features_from_text(text,poslist),cl) for text,cl in train_data_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'has': 0.07462686567164178,\n",
       "  'been': 0.07462686567164178,\n",
       "  'written': 0.014925373134328358,\n",
       "  'is': 0.14925373134328357,\n",
       "  'explains': 0.014925373134328358,\n",
       "  'are': 0.029850746268656716,\n",
       "  'swamped': 0.014925373134328358,\n",
       "  'including': 0.014925373134328358,\n",
       "  'upcoming': 0.014925373134328358,\n",
       "  'gives': 0.029850746268656716,\n",
       "  'learns': 0.014925373134328358,\n",
       "  'takes': 0.014925373134328358,\n",
       "  'shakespeare': 0.014925373134328358,\n",
       "  \"'ve\": 0.029850746268656716,\n",
       "  'married': 0.014925373134328358,\n",
       "  'anne': 0.014925373134328358,\n",
       "  'had': 0.014925373134328358,\n",
       "  'played': 0.014925373134328358,\n",
       "  'struggling': 0.014925373134328358,\n",
       "  'come': 0.014925373134328358,\n",
       "  'does': 0.014925373134328358,\n",
       "  'quite': 0.014925373134328358,\n",
       "  'seem': 0.014925373134328358,\n",
       "  'changes': 0.014925373134328358,\n",
       "  'writes': 0.014925373134328358,\n",
       "  'viola': 0.014925373134328358,\n",
       "  'parallels': 0.014925373134328358,\n",
       "  'paltrow': 0.014925373134328358,\n",
       "  'develop': 0.014925373134328358,\n",
       "  'smoothes': 0.014925373134328358,\n",
       "  'filled': 0.014925373134328358,\n",
       "  'tom': 0.014925373134328358,\n",
       "  'affleck': 0.014925373134328358,\n",
       "  'leading': 0.014925373134328358,\n",
       "  'manages': 0.014925373134328358,\n",
       "  'make': 0.029850746268656716,\n",
       "  'judi': 0.014925373134328358,\n",
       "  'lends': 0.014925373134328358,\n",
       "  'creating': 0.014925373134328358,\n",
       "  'flirts': 0.014925373134328358,\n",
       "  'lighthearted': 0.014925373134328358,\n",
       "  \"'s\": 0.014925373134328358,\n",
       "  'making': 0.014925373134328358,\n",
       "  'inspiring': 0.014925373134328358,\n",
       "  'revels': 0.014925373134328358,\n",
       "  'absent': 0.014925373134328358},\n",
       " 'pos')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docfreq = Counter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
