{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In dem Aufgaben finden Sie 2 Dateien. Die Dateien enthalten englische Reviews von Filmen. Die eine Datei enthält negative die andere positive Reviews. \n",
    "\n",
    "Wir wollen einen Klassifikator bauen, der vorhersagt, ob ein Review positiv oder negativ ist. Machen Sie dazu folgendes:\n",
    "\n",
    "1. Teilen Sie die Daten in Test und Trainingsdaten ein.\n",
    "2. Extrahieren Sie alle Adjektive, Verben und Adverbien aus den Reviews\n",
    "3. Nutzen Sie alle Adjektive, Verben und Adverbien, die mindesten 5 Mal vorkommen als Merkmale und Trainieren Sie einen Klassifikator, der logistische Regression nutzt.\n",
    "5. Evaluieren Sie den Klassifikator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lösung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs \n",
    "\n",
    "def readtext(dateiname):\n",
    "    text = ''\n",
    "    d = codecs.open(dateiname,'r','utf8')\n",
    "    for zeile in d:\n",
    "        text += str(zeile)\n",
    "    d.close()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def read_data(directories):\n",
    "    docs = []\n",
    "    for directory in directories:\n",
    "        for file in glob.glob(directory+\"/*.txt\"):\n",
    "            text = readtext(file)\n",
    "            docs.append((text,directory))\n",
    "    return docs\n",
    "\n",
    "data = read_data(['neg','pos'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teilen Sie die Daten in Test und Trainingsdaten ein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def features_from_text(text, POSlist):\n",
    "    \n",
    "    wordcounts = Counter()\n",
    "    tlen = 0\n",
    "    \n",
    "    sentlist = nltk.sent_tokenize(text,language='english')\n",
    "    for sent in sentlist:\n",
    "        tokens = nltk.word_tokenize(sent,language='english')\n",
    "        tokens = [word for (word,pos) in nltk.pos_tag(tokens) if pos in POSlist]\n",
    "        tokens = [t for t in tokens if t.lower() not in stopwords]\n",
    "        tokens = [t for t in tokens if re.search('^\\w+$',t)]\n",
    "        wordcounts.update(tokens)\n",
    "        tlen +=len(tokens)\n",
    "    return {w:wordcounts[w]/tlen for w in wordcounts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(data)\n",
    "train_data_raw = data[1000:]\n",
    "test_data_raw = data[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poslist = ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ','RB', 'RBR', 'RBS','JJ', 'JJR', 'JJS']\n",
    "# poslist = ['RB', 'RBR', 'RBS']\n",
    "# poslist = ['JJ', 'JJR', 'JJS']\n",
    "\n",
    "\n",
    "test_data = [(features_from_text(text,poslist),cl) for text,cl in test_data_raw]\n",
    "train_data = [(features_from_text(text,poslist),cl) for text,cl in train_data_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docfreq = Counter()\n",
    "for (wfreq,c) in train_data:\n",
    "    docfreq.update(wfreq.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docfreq.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model, datasets\n",
    "\n",
    "allfeatures = [w for w in docfreq if docfreq[w] > 4]\n",
    "\n",
    "def make_feat_vec(featmap,featlist):\n",
    "    vec = []\n",
    "    for f in featlist:\n",
    "        vec.append(featmap.get(f,0.0))\n",
    "    return vec\n",
    "\n",
    "train_vec =  [make_feat_vec(feats,allfeatures) for feats,cls in train_data]\n",
    "train_label = [cls for feats,cls in train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vec[86]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label[86]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logreg = linear_model.LogisticRegression(C=1e9,verbose=True, max_iter=2000)\n",
    "logreg.fit(train_vec,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vec = [make_feat_vec(feats,allfeatures) for feats,cls in test_data]\n",
    "test_label = [cls for feats,cls in test_data]\n",
    "\n",
    "pred_label = list(logreg.predict(test_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for i in range(len(test_label)):\n",
    "    if test_label[i] == pred_label[i]:\n",
    "        correct+=1\n",
    "print(\"{0:.1f} Prozent korrekt\".format(100* float(correct)/len(test_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = make_feat_vec(test_data[2][0],allfeatures) \n",
    "logreg.predict([v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
