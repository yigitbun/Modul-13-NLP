{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In dem Aufgaben finden Sie 2 Dateien. Die Dateien enthalten englische Reviews von Filmen. Die eine Datei enthält negative die andere positive Reviews. \n",
    "\n",
    "Wir wollen einen Klassifikator bauen, der vorhersagt, ob ein Review positiv oder negativ ist. Machen Sie dazu folgendes:\n",
    "\n",
    "1. Teilen Sie die Daten in Test und Trainingsdaten ein.\n",
    "2. Extrahieren Sie alle Adjektive, Verben und Adverbien aus den Reviews\n",
    "3. Nutzen Sie alle Adjektive, Verben und Adverbien, die mindesten 5 Mal vorkommen als Merkmale und Trainieren Sie einen Klassifikator, der logistische Regression nutzt.\n",
    "5. Evaluieren Sie den Klassifikator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lösung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs \n",
    "\n",
    "def readtext(dateiname):\n",
    "    text = ''\n",
    "    d = codecs.open(dateiname,'r','utf8')\n",
    "    for zeile in d:\n",
    "        text += str(zeile)\n",
    "    d.close()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def read_data(directories):\n",
    "    docs = []\n",
    "    for directory in directories:\n",
    "        for file in glob.glob(directory+\"/*.txt\"):\n",
    "            text = readtext(file)\n",
    "            docs.append((text,directory))\n",
    "    return docs\n",
    "\n",
    "data = read_data(['pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def closed_class(pos):\n",
    "    if pos[0] == '$':\n",
    "        return True\n",
    "    # elif pos in [\"NE\",\"ADJA\",\"RB\",\"APPR\", \"APPRART\", \"APPO\", \"APZR\", \"ART\", \"KOUI\", \"KOUS\", \"KON\", \"KOKOM\", \"PDS\", \"PDAT\", \"PIS\", \"PIAT\", \"PIDAT\", \"PPER\", \"PPOSS\", \"PPOSAT\", \"PRELS\", \"PRELAT\", \"PRF\", \"PWS\", \"PWAT\", \"PWAV\", \"PAV\", \"PTKZU\", \"PTKNEG\", \"VAFIN\", \"VAIMP\", \"VAINF\", \"VAPP\", \"VMFIN\", \"VMINF\", \"VMPP\"]:\n",
    "    #    return True\n",
    "    elif pos not in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']:\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def features_from_text(text):\n",
    "    wordcounts = Counter()\n",
    "    tlen = 0\n",
    "    \n",
    "    satzliste =  nltk.sent_tokenize(text,language='english')\n",
    "    for satz in satzliste:\n",
    "        tokens =  nltk.word_tokenize(satz,language='english')\n",
    "        #tokens = [lemma for (word,lemma,pos) in tagger.tag_sent(tokens) if not closed_class(pos)]\n",
    "        #tokens = [t for t in tokens if t.lower() not in stopwords]\n",
    "        tokens = [t for t in tokens if re.search('^\\w+$',t)]\n",
    "        tlen += len(tokens)\n",
    "        wordcounts.update(tokens)\n",
    "\n",
    "    return {w:wordcounts[w]/tlen for w in wordcounts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def read_data(directories):\n",
    "    docs = []\n",
    "    for directory in directories:\n",
    "        for file in glob.glob(directory+\"/*.txt\"):\n",
    "            text = readtext(file)\n",
    "            docs.append((features_from_text(text),directory))\n",
    "    return docs\n",
    "\n",
    "data = read_data(['pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'assume': 0.0012642225031605564, 'nothing': 0.0012642225031605564, 'the': 0.05056890012642225, 'phrase': 0.0037926675094816687, 'is': 0.03666245259165613, 'perhaps': 0.0012642225031605564, 'one': 0.007585335018963337, 'of': 0.02402022756005057, 'most': 0.0025284450063211127, 'used': 0.0025284450063211127, '1990': 0.0012642225031605564, 'as': 0.018963337547408345, 'first': 0.0012642225031605564, 'impressions': 0.0012642225031605564, 'and': 0.0316055625790139, 'rumors': 0.0025284450063211127, 'are': 0.006321112515802781, 'hardly': 0.0012642225031605564, 'ever': 0.0012642225031605564, 'what': 0.0025284450063211127, 'they': 0.0012642225031605564, 'seem': 0.0025284450063211127, 'to': 0.03413400758533502, 'be': 0.0025284450063211127, 'especially': 0.0012642225031605564, 'goes': 0.0025284450063211127, 'for': 0.008849557522123894, 'oscar': 0.018963337547408345, 'novak': 0.0037926675094816687, 'an': 0.0050568900126422255, 'architect': 0.0025284450063211127, 'who': 0.006321112515802781, 'main': 0.0012642225031605564, 'focus': 0.0012642225031605564, 'three': 0.011378002528445006, 'tango': 0.011378002528445006, 'a': 0.02402022756005057, 'delightful': 0.0025284450063211127, 'funny': 0.0025284450063211127, 'romantic': 0.0050568900126422255, 'comedy': 0.008849557522123894, 'about': 0.0012642225031605564, 'assumptions': 0.0012642225031605564, 'being': 0.0025284450063211127, 'yourself': 0.0012642225031605564, 'matthew': 0.0025284450063211127, 'perry': 0.0050568900126422255, 'shy': 0.0025284450063211127, 'clumsy': 0.0012642225031605564, 'chicago': 0.0012642225031605564, 'based': 0.0037926675094816687, 'along': 0.0012642225031605564, 'with': 0.010113780025284451, 'openly': 0.0012642225031605564, 'gay': 0.008849557522123894, 'partner': 0.0012642225031605564, 'peter': 0.0012642225031605564, 'steinberg': 0.0012642225031605564, 'oliver': 0.0012642225031605564, 'platt': 0.0012642225031605564, 'fights': 0.0012642225031605564, 'projects': 0.0012642225031605564, 'day': 0.0025284450063211127, 'in': 0.01390644753476612, 'out': 0.0037926675094816687, 'these': 0.0012642225031605564, 'job': 0.0037926675094816687, 'restoring': 0.0012642225031605564, 'popular': 0.0025284450063211127, 'building': 0.0012642225031605564, 'charles': 0.008849557522123894, 'newman': 0.0012642225031605564, 'dylan': 0.0037926675094816687, 'mcdermott': 0.0037926675094816687, 'rich': 0.0012642225031605564, 'businessman': 0.0012642225031605564, 'immediately': 0.0025284450063211127, 'takes': 0.0025284450063211127, 'liking': 0.0012642225031605564, 'he': 0.017699115044247787, 'enjoys': 0.0012642225031605564, 'his': 0.012642225031605562, 'personality': 0.0025284450063211127, 'sense': 0.0012642225031605564, 'humor': 0.0012642225031605564, 'seeing': 0.0025284450063211127, 'someone': 0.0025284450063211127, 'could': 0.0025284450063211127, 'trust': 0.0012642225031605564, 'asks': 0.0012642225031605564, 'him': 0.0037926675094816687, 'watch': 0.0012642225031605564, 'girlfriend': 0.0012642225031605564, 'unpredictable': 0.0012642225031605564, 'adventurous': 0.0012642225031605564, 'girl': 0.0012642225031605564, 'named': 0.0012642225031605564, 'amy': 0.006321112515802781, 'post': 0.0012642225031605564, 'neve': 0.0050568900126422255, 'campbell': 0.0050568900126422255, 'makes': 0.0012642225031605564, 'living': 0.0012642225031605564, 'by': 0.0037926675094816687, 'blowing': 0.0012642225031605564, 'glass': 0.0012642225031605564, 'wants': 0.0012642225031605564, 'know': 0.0012642225031605564, 'she': 0.007585335018963337, 'talks': 0.0012642225031605564, 'does': 0.0037926675094816687, 'where': 0.0012642225031605564, 'point': 0.0012642225031605564, 'make': 0.0012642225031605564, 'sure': 0.0012642225031605564, 'not': 0.006321112515802781, 'else': 0.0025284450063211127, 'course': 0.0012642225031605564, 'gladly': 0.0012642225031605564, 'meets': 0.0012642225031605564, 'at': 0.0025284450063211127, 'art': 0.0012642225031605564, 'show': 0.0012642225031605564, 'hers': 0.0012642225031605564, 'sparks': 0.0012642225031605564, 'fly': 0.0012642225031605564, 'between': 0.0025284450063211127, 'two': 0.0025284450063211127, 'from': 0.0025284450063211127, 'get': 0.0012642225031605564, 'go': 0.0012642225031605564, 'feels': 0.0025284450063211127, 'has': 0.0025284450063211127, 'found': 0.0012642225031605564, 'meant': 0.0012642225031605564, 'content': 0.0012642225031605564, 'idea': 0.0012642225031605564, 'well': 0.0037926675094816687, 'another': 0.0012642225031605564, '90': 0.0012642225031605564, 'all': 0.0012642225031605564, 'good': 0.0012642225031605564, 'things': 0.0012642225031605564, 'must': 0.0012642225031605564, 'come': 0.0037926675094816687, 'end': 0.0012642225031605564, 'this': 0.008849557522123894, 'stays': 0.0012642225031605564, 'true': 0.0012642225031605564, 'walks': 0.0012642225031605564, 'on': 0.0050568900126422255, 'having': 0.0012642225031605564, 'drink': 0.0012642225031605564, 'night': 0.0012642225031605564, 'have': 0.0037926675094816687, 'become': 0.0012642225031605564, 'great': 0.0025284450063211127, 'friends': 0.0025284450063211127, 'but': 0.006321112515802781, 'mind': 0.0012642225031605564, 'why': 0.0012642225031605564, 'thinks': 0.0012642225031605564, 'afraid': 0.0012642225031605564, 'share': 0.0012642225031605564, 'either': 0.0012642225031605564, 'stands': 0.0012642225031605564, 'shock': 0.0012642225031605564, 'after': 0.0012642225031605564, 'words': 0.0012642225031605564, 'i': 0.0037926675094816687, 'swear': 0.0012642225031605564, 'if': 0.0025284450063211127, 'you': 0.0037926675094816687, 'were': 0.0025284450063211127, 'kill': 0.0012642225031605564, 'muttered': 0.0012642225031605564, 'flamboyantly': 0.0012642225031605564, 'mouth': 0.0012642225031605564, 'word': 0.0012642225031605564, 'spreads': 0.0012642225031605564, 'instantly': 0.0012642225031605564, 'through': 0.0012642225031605564, 'town': 0.0012642225031605564, 'will': 0.0025284450063211127, 'supposed': 0.0012642225031605564, 'gayness': 0.0012642225031605564, 'or': 0.0050568900126422255, 'tell': 0.0012642225031605564, 'everyone': 0.0012642225031605564, 'that': 0.010113780025284451, 'would': 0.0037926675094816687, 'think': 0.0025284450063211127, 'deny': 0.0012642225031605564, 'fact': 0.0037926675094816687, 'numerous': 0.0012642225031605564, 'occurrences': 0.0012642225031605564, 'which': 0.0025284450063211127, 'result': 0.0012642225031605564, 'denies': 0.0012642225031605564, 'lose': 0.0012642225031605564, 'escape': 0.0012642225031605564, 'character': 0.006321112515802781, 'chandler': 0.0025284450063211127, 'already': 0.0012642225031605564, 'classic': 0.0012642225031605564, 't': 0.0025284450063211127, 'v': 0.0025284450063211127, 'both': 0.0012642225031605564, 'clueless': 0.0012642225031605564, 'sensitive': 0.0012642225031605564, 'nonetheless': 0.0012642225031605564, 'hilarious': 0.0037926675094816687, 'here': 0.0050568900126422255, 'shows': 0.0012642225031605564, 'can': 0.0012642225031605564, 'handle': 0.0012642225031605564, 'drama': 0.0025284450063211127, 'obviously': 0.0012642225031605564, 'suffers': 0.0012642225031605564, 'quite': 0.0012642225031605564, 'bit': 0.0012642225031605564, 'it': 0.0025284450063211127, 'wonderful': 0.0025284450063211127, 'see': 0.0012642225031605564, 'outside': 0.0012642225031605564, 'horror': 0.0012642225031605564, 'movie': 0.0012642225031605564, 'was': 0.0025284450063211127, 'star': 0.0012642225031605564, 'scream': 0.0025284450063211127, '1': 0.0012642225031605564, '2': 0.0012642225031605564, 'upcoming': 0.0012642225031605564, '3': 0.0012642225031605564, 'handles': 0.0012642225031605564, 'superbly': 0.0012642225031605564, 'her': 0.0037926675094816687, 'voice': 0.0012642225031605564, 'smile': 0.0012642225031605564, 'more': 0.0012642225031605564, 'than': 0.0012642225031605564, 'perfect': 0.0012642225031605564, 'stay': 0.0012642225031605564, 'genre': 0.0012642225031605564, 'conflicted': 0.0012642225031605564, 'love': 0.0012642225031605564, 'knows': 0.0012642225031605564, 'usual': 0.0012642225031605564, 'likable': 0.0025284450063211127, 'unlike': 0.0025284450063211127, 'other': 0.0012642225031605564, 'leads': 0.0012642225031605564, 'flat': 0.0012642225031605564, 'dialogue': 0.0025284450063211127, 'never': 0.0025284450063211127, 'convincing': 0.0012642225031605564, 'when': 0.0012642225031605564, 'present': 0.0012642225031605564, 'sets': 0.0012642225031605564, 'dull': 0.0012642225031605564, 'tone': 0.0012642225031605564, 'scene': 0.0025284450063211127, 'horrible': 0.0012642225031605564, 'acting': 0.0012642225031605564, 'stick': 0.0012642225031605564, 'practice': 0.0012642225031605564, 'major': 0.0012642225031605564, 'weak': 0.0012642225031605564, 'spot': 0.0012642225031605564, 'direction': 0.0012642225031605564, 'damon': 0.0012642225031605564, 'santostefano': 0.0012642225031605564, 'no': 0.0012642225031605564, 'originality': 0.0012642225031605564, 'technique': 0.0012642225031605564, 'whatsoever': 0.0012642225031605564, 'lucky': 0.0012642225031605564, 'script': 0.0037926675094816687, 'so': 0.0037926675094816687, 'edgy': 0.0012642225031605564, 'film': 0.0025284450063211127, 'been': 0.0025284450063211127, 'disaster': 0.0012642225031605564, 'just': 0.0012642225031605564, 'plain': 0.0012642225031605564, 'boring': 0.0012642225031605564, 'look': 0.0012642225031605564, 'done': 0.0012642225031605564, 'many': 0.0012642225031605564, 'times': 0.0012642225031605564, 'before': 0.0012642225031605564, 'plot': 0.0025284450063211127, 'suspiciously': 0.0012642225031605564, 'close': 0.0012642225031605564, '1998': 0.0012642225031605564, 'object': 0.0012642225031605564, 'my': 0.0012642225031605564, 'affection': 0.0012642225031605564, 'completed': 0.0012642225031605564, 'written': 0.0012642225031605564, 'rodney': 0.0012642225031605564, 'patrick': 0.0012642225031605564, 'vaccaro': 0.0012642225031605564, 'aline': 0.0012642225031605564, 'brosh': 0.0012642225031605564, 'mckenna': 0.0012642225031605564, 'fun': 0.0012642225031605564, 'fast': 0.0012642225031605564, 'delivering': 0.0012642225031605564, 'only': 0.0012642225031605564, 'original': 0.0012642225031605564, 'jokes': 0.0012642225031605564, 'your': 0.0012642225031605564, 'run': 0.0012642225031605564, 'mill': 0.0012642225031605564, 'material': 0.0012642225031605564, 'certain': 0.0012642225031605564, 'snappiness': 0.0012642225031605564, 'characters': 0.0012642225031605564, 'always': 0.0012642225031605564, 'keeps': 0.0012642225031605564, 'smiling': 0.0012642225031605564, 'last': 0.0012642225031605564, 'summer': 0.0012642225031605564, 'south': 0.0012642225031605564, 'park': 0.0012642225031605564, 'bigger': 0.0012642225031605564, 'longer': 0.0012642225031605564, 'uncut': 0.0012642225031605564, '1997': 0.0012642225031605564, 'element': 0.0012642225031605564, 'crude': 0.0012642225031605564, 'vulgar': 0.0012642225031605564, 'wise': 0.0012642225031605564, 'take': 0.0012642225031605564, 'route': 0.0012642225031605564, 'gays': 0.0012642225031605564, 'ca': 0.0012642225031605564, 'do': 0.0012642225031605564, 'anyway': 0.0012642225031605564, 'offended': 0.0012642225031605564, 'light': 0.0025284450063211127, 'playful': 0.0012642225031605564, 'prove': 0.0012642225031605564, 'couple': 0.0012642225031605564, 'audience': 0.0012642225031605564, 'laughing': 0.0012642225031605564, 'constantly': 0.0012642225031605564, 'climax': 0.0012642225031605564, 'clever': 0.0012642225031605564, 'pure': 0.0012642225031605564, 'irony': 0.0012642225031605564, 'outcome': 0.0012642225031605564, 'identity': 0.0012642225031605564, 'comedies': 0.0025284450063211127, 'gem': 0.0012642225031605564, 'bottom': 0.0012642225031605564, 'line': 0.0012642225031605564, 'sharp': 0.0012642225031605564, 'snappy': 0.0012642225031605564, 'superb': 0.0012642225031605564, 'ending': 0.0012642225031605564, 'stars': 0.0012642225031605564, 'better': 0.0012642225031605564, '1999': 0.0012642225031605564}, 'pos')\n"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c22fc181e821>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtextfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"utf-8-sig\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtextfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtextfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/codecs.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, encoding, errors, buffering)\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[0;31m# Force opening of the file in binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m         \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not list"
     ]
    }
   ],
   "source": [
    "textfile = codecs.open(data, \"r\", \"utf-8-sig\")\n",
    "text = textfile.read()\n",
    "textfile.close()\n",
    "\n",
    "sentences = nltk.sent_tokenize(text,language='english')\n",
    "\n",
    "tokenized_text = [nltk.word_tokenize(sent, language='english') for sent in sentences]\n",
    "\n",
    "print(tokenized_text[0])\n",
    "print(tokenized_text[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
