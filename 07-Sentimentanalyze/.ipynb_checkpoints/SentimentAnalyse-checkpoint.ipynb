{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentimentanalyse\n",
    "\n",
    "Sentimentanalyse, auch _Opinion Mining_ genannt, ist das herausfinden der Meinung, die in einem Text zu igendetwas geäußert wird.\n",
    "\n",
    "Es werden zwei Dimensionen, entlang denen Text klassifiziert werden können, unterschieden: \n",
    " * Objektiv vs. Subjektiv und \n",
    " * Negativ - Neutral - Positiv.\n",
    "\n",
    "Längere Texte können natürlich mehrere Meinungen zu den gleichen und zu verschiedenen Sachen enthalten. Im folgenden machen wir mal die vereinfachende Annahme, das Texte immer homogen sind. \n",
    "\n",
    "Unsere einfache Hypothese ist, dass es Wörter gibt, die eine stark positives oder negatives Sentiment verkörpern, und das es reicht diese Wörter zu finden, um einen Text zu klassifizieren. Diese Annahme ist natürlich nicht ganz korrekt. Eine positive ode negative Meinung hängt natürlich von mehr als nur von einzelnen Wörtern ab: insbesondere  Negation kann die Bedeutung eines Wortes grundlegend ändern. Einige ganz neue Verfahren (Stichwörter: ELMO und BERT) können auch mit der unterschiedliche Bedeutung von Wörtern in Abhängigkeit der umgebenden Wörter umgehen. Wir kommen aber schon ganz weit, wenn wir nur einzelne Wörter verwenden. Verfahren, die nur einzelne Wörter verwenden, ohne ihre Beziehungen zu berücksichtigen, nennt man übrigens _Bag of Word_-Verfahren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es gibt nun zwei Möglichkeiten die Idee umzusetzen:\n",
    "1. Wir trainieren einen Classifier, der aus Beispieltexten lernt, wie viel jedes Wort zum positiven oder negativen Sentiment beiträgt. Der Vorteil dieser Methode ist, dass wie genaue gewichte für eine spezifische Domäne oder Textart lernen können. Der Nachteil ist, dass wir Texte brauchen, die händisch beuurteilt wurden.\n",
    "2. Wir nutzen allgemeine Listen mit positiven und negativen Wörtern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "Für die Sentimentanalyse brauchen wir in Grunde genommen nur Listen mit positiven und negativen Wörtern und eine Funktion, die zählt wie viele positive und negative Wörter es in einem Text gibt. Es gibt aber auch Tools, die das alles ganz unkomplziert für uns erledigen können. Für die Sentimentanalyse können wir die Bibiothek _TextBlob_ nutzen.\n",
    "\n",
    "Das ist jetzt die dritte Bibliothek für NLP. Was sind die Unterschiede?\n",
    "\n",
    "* NLTK: Eine Sammlung mit sehr vielen Algorithmen, meistens sprachunabhängig oder für viele Sprachen geeignet. Oft auch viele unterschiedliche Algorithmen für dieselbe Aufgabe. Ein Eldorado für Experte, die experimentieren und selber neue Anwendungen entwickeln wollen.\n",
    "* TextBlob: eine Auswahl von Algorithmen aus NLTK, die zusammen eine Standard-Analyse eines Textes für einige wenige Sprachen ausführen können. Wenig Vorwissn erforderlich, einfach einzusetzen, aber ohne Möglichkeiten, etwas anzupassen.\n",
    "* Spacy: von der Idee und Funktionalität sehr ähnlich zu TextBlob, etwas umfangreicher und vorallem mit eigener sehr performante Implementierung.\n",
    "\n",
    "Weder NLTK noch Spacy enthalten eine fertig eingebaute Sentimentanalyse für Deutsche Texte. TextBlob bietet diese Funktionalität aber. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textanalyse mit TextBlob\n",
    "\n",
    "Zunächst installieren wir die Deutsche Version von TextBlob:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: textblob-de==0.4.3 in c:\\users\\wartena\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (0.4.3)\n",
      "Requirement already satisfied, skipping upgrade: textblob>=0.9.0 in c:\\users\\wartena\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from textblob-de==0.4.3) (0.15.3)\n",
      "Requirement already satisfied, skipping upgrade: nltk>=3.1 in c:\\users\\wartena\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from textblob>=0.9.0->textblob-de==0.4.3) (3.4)\n",
      "Requirement already satisfied, skipping upgrade: six in c:\\users\\wartena\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob>=0.9.0->textblob-de==0.4.3) (1.13.0)\n",
      "Requirement already satisfied, skipping upgrade: singledispatch in c:\\users\\wartena\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob>=0.9.0->textblob-de==0.4.3) (3.4.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U textblob-de==0.4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\wartena\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\wartena\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\wartena\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\wartena\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     C:\\Users\\wartena\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\wartena\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir nehmen mal drei kurze Texte, und schauen, was TextBlob damit so macht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "text =  '''Wer braucht diese Bücher mit ihren Plattheiten?\n",
    "Eine Zumutung für Leser mit einem gewissen Anspruch.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieser Text laden wir jetzt in ein TextBlob-Objekt. Dabei wird dieser Text vollständig analysiert. Anschließend können wir die Analzsen aus dem Objekt auslesen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textblob\n",
    "from textblob_de import TextBlobDE\n",
    "\n",
    "blob = TextBlobDE(text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"Wer braucht diese Bücher mit ihren Plattheiten?\"),\n",
       " Sentence(\"Eine Zumutung für Leser mit einem gewissen Anspruch.\")]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Wer', 'braucht', 'diese', 'Bücher', 'mit', 'ihren', 'Plattheiten', '?', 'Eine', 'Zumutung', 'für', 'Leser', 'mit', 'einem', 'gewissen', 'Anspruch', '.'])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Wer', 'WP'),\n",
       " ('braucht', 'VB'),\n",
       " ('diese', 'DT'),\n",
       " ('Bücher', 'NN'),\n",
       " ('mit', 'IN'),\n",
       " ('ihren', 'PRP$'),\n",
       " ('Plattheiten', 'NN'),\n",
       " ('Eine', 'DT'),\n",
       " ('Zumutung', 'NN'),\n",
       " ('für', 'IN'),\n",
       " ('Leser', 'NN'),\n",
       " ('mit', 'IN'),\n",
       " ('einem', 'DT'),\n",
       " ('gewissen', 'JJ'),\n",
       " ('Anspruch', 'NN')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.0, subjectivity=0.0)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'wer': 1,\n",
       "             'braucht': 1,\n",
       "             'diese': 1,\n",
       "             'bücher': 1,\n",
       "             'mit': 2,\n",
       "             'ihren': 1,\n",
       "             'plattheiten': 1,\n",
       "             'eine': 1,\n",
       "             'zumutung': 1,\n",
       "             'für': 1,\n",
       "             'leser': 1,\n",
       "             'einem': 1,\n",
       "             'gewissen': 1,\n",
       "             'anspruch': 1})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['wer', 'brauchen', 'dies', 'Bücher', 'mit', 'ihren', 'Plattheiten', 'Ein', 'Zumutung', 'für', 'Leser', 'mit', 'ein', 'gewiss', 'Anspruch'])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.words.lemmatize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          WORD   TAG    CHUNK   ROLE   ID     PNP    LEMMA           \n",
      "                                                                     \n",
      "           bin   VB     VP      -      -      -      sein            \n",
      "         etwas   DT     -       -      -      -      etwas           \n",
      "    enttäuscht   JJ     ADJP    -      -      -      enttäuscht      \n",
      "          nach   IN     PP      -      -      -      nach            \n",
      "         allem   DT     -       -      -      -      all             \n",
      "           was   WDT    NP      -      -      -      was             \n",
      "           ich   PRP    NP ^    -      -      -      ich             \n",
      "          über   IN     PP      -      -      PNP    über            \n",
      "           das   DT     NP      -      -      PNP    das             \n",
      "          Buch   NN     NP ^    -      -      PNP    buch            \n",
      "       gelesen   VB     VP      -      -      -      lesen           \n",
      "           hab   NN     NP      -      -      -      hab             \n",
      "             .   .      -       -      -      -      .               \n",
      "     Langatmig   JJ     ADJP    -      -      -      langatmig       \n",
      "           und   CC     -       -      -      -      und             \n",
      "           die   DT     NP      -      -      -      die             \n",
      " Protagonisten   NN     NP ^    -      -      -      protagonisten   \n",
      "      allesamt   NN     NP ^    -      -      -      allesamt        \n",
      "          dazu   VB     VP      -      -      -      dazuen          \n",
      "             .   .      -       -      -      -      .               \n"
     ]
    }
   ],
   "source": [
    "from textblob_de import PatternParser\n",
    "blob = TextBlobDE(text1, parser=PatternParser(pprint=True, lemmata=True))\n",
    "blob.parse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"\"\"bin etwas enttäuscht nach allem was ich über das Buch gelesen \n",
    "hab. Langatmig und die Protagonisten allesamt dazu. \"\"\"\n",
    "blob1 = TextBlobDE(text1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-0.5, subjectivity=0.0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob1.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 =  '''Es ist wieder ein hervorragender Roman in einer \n",
    "guten und wunderbaren Schreibweise in guter Übersetzung.'''\n",
    "blob2 = TextBlobDE(text2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=1.0, subjectivity=0.0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob2.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 =  '''Wer braucht diese Bücher mit ihren Plattheiten?\n",
    "Eine Zumutung für Leser mit einem gewissen Anspruch.'''\n",
    "blob3 = TextBlobDE(text3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.0, subjectivity=0.0)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob3.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "text4 =  '''Schon am Beginn dieses Buches kann man erahnen, dass durch den Tod des befreundeten örtlichen \n",
    "Bankiers die Geldprobleme des Hotels schlagend werden und letztlich trotz des Ignorierens der fatalens \n",
    "finanziellen Situation der Konklurs und somit der Untergang einer einstigen Institution ihr finales Ende findet.\n",
    "\n",
    "Sprachlich großartig, teilweise mit viel Wortwitz und spannend geschrieben. Probleme werden geschildert und \n",
    "dann bleibt die Spannung über viele Seiten aufrecht, um dann dem Leser die Lösung zu bieten.\n",
    "\n",
    "Diese ganze Geschichte findet in einer wunderschönen Landschaft statt, die ich auch persönlich kenne und mir \n",
    "dadurch noch mehr Freude beim Lesen geboten wurde. Auch beim Ausflug nach Oslo werden Straßen und Gebäude so\n",
    "punktgenau beschrieben, dass man den Eindruck den beiden Reisenden hinterher zu gehen. '''\n",
    "blob4 = TextBlobDE(text4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.21333333333333332, subjectivity=0.36666666666666664)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob4.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "text5 =  '''Viel gelobtes Werk. Ich fand es ehrlich gesagt etwas langweilig. Dieser kreuzbrave allen nach dem \n",
    "Munde redende Junge, die nervtötende Großmutter und der Großvater mit seinen Weisheiten sind schnell beschrieben. \n",
    "Dann folgen ewige langatmige Beschreibungen von - meiner Meinung nach - der Handlung wenig dienenden Betrachtungen,\n",
    "z. B. im Museum in Oslo. Das alles ist allzu wortreich. Und, das fragt man sich zunehmend ungeduldig, worum geht \n",
    "es eigentlich. Warum fragt er nicht einfach nach dem Schlüssel zu dieser Tür da oben im Hotel. Warum rebelliert er\n",
    "nicht, was normal wäre für einen pubertierenden Jungen. Warum reden die angelblich so liebevollen Großeltern nicht\n",
    "mit dem Kind, als hätten sie da oben in Norwegen noch nie was von Pädagogik oder Erziehung gehört (gerade dort!) \n",
    "Und alles wird verkauft als \"großelterliche Liebe\" - das nervt.\n",
    "\n",
    "Alles in allem viel zu viel Drumherum, eher quälende Lektüre als wirklich gute Unterhaltung.. '''\n",
    "blob5 = TextBlobDE(text5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.23749999999999996, subjectivity=0.125)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob5.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
